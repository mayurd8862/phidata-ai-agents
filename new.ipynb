{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> No Serpapi API key provided                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING \u001b[0m No Serpapi API key provided                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3866bc65e6264e6f8c83062ab57eb19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.tools.serpapi_tools import SerpApiTools\n",
    "\n",
    "web_agent = Agent(\n",
    "    name=\"Web Agent\",\n",
    "    model=Groq(id=\"llama3-70b-8192\"),\n",
    "    tools=[SerpApiTools()],\n",
    "    instructions=[\"Always include sources\"],\n",
    "    show_tool_calls=True,\n",
    "    monitoring= True,\n",
    "    markdown=True,\n",
    ")\n",
    "web_agent.print_response(\"who is the pm of india\", stream=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Debug logs enabled                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Debug logs enabled                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> *********** Agent Run Start: <span style=\"color: #ffff00; text-decoration-color: #ffff00\">91c09a42-8fd3-4309-a406-68a07dcd7e1a</span> ***********                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m *********** Agent Run Start: \u001b[93m91c09a42-8fd3-4309-a406-68a07dcd7e1a\u001b[0m ***********                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a429ba5d2a49798dbc2ccfdf544a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Function google_search from googlesearch added to model.                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Function google_search from googlesearch added to model.                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ---------- OpenAI Response Start ----------                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ---------- OpenAI Response Start ----------                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== system ==============                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== system ==============                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> You are a news agent that helps users find the latest news.                                               \n",
       "                                                                                                                   \n",
       "         ## Instructions                                                                                           \n",
       "         - Given a topic by the user, respond with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> latest news items about that topic.                           \n",
       "         - Search for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> news items and select the top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> unique items.                                             \n",
       "         - Search in English and in French.                                                                        \n",
       "         - Use markdown to format your answers.                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m You are a news agent that helps users find the latest news.                                               \n",
       "                                                                                                                   \n",
       "         ## Instructions                                                                                           \n",
       "         - Given a topic by the user, respond with \u001b[1;36m4\u001b[0m latest news items about that topic.                           \n",
       "         - Search for \u001b[1;36m10\u001b[0m news items and select the top \u001b[1;36m4\u001b[0m unique items.                                             \n",
       "         - Search in English and in French.                                                                        \n",
       "         - Use markdown to format your answers.                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== user ==============                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== user ==============                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Mistral AI                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Mistral AI                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mERROR   \u001b[0m OPENAI_API_KEY not set. Please set the OPENAI_API_KEY environment variable.                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mphi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgooglesearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleSearch\n\u001b[0;32m      4\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[0;32m      5\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[GoogleSearch()],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# model=Groq(id=\"llama3-70b-8192\"),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     debug_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMistral AI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkdown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayur\\Desktop\\Project\\phidata AI Agents\\venv\\Lib\\site-packages\\phi\\agent\\agent.py:2904\u001b[0m, in \u001b[0;36mAgent.print_response\u001b[1;34m(self, message, messages, stream, markdown, show_message, show_reasoning, show_full_reasoning, console, **kwargs)\u001b[0m\n\u001b[0;32m   2901\u001b[0m     live_log\u001b[38;5;241m.\u001b[39mupdate(Group(\u001b[38;5;241m*\u001b[39mpanels))\n\u001b[0;32m   2903\u001b[0m \u001b[38;5;66;03m# Run the agent\u001b[39;00m\n\u001b[1;32m-> 2904\u001b[0m run_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2905\u001b[0m response_timer\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m   2907\u001b[0m reasoning_steps \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\mayur\\Desktop\\Project\\phidata AI Agents\\venv\\Lib\\site-packages\\phi\\agent\\agent.py:2070\u001b[0m, in \u001b[0;36mAgent.run\u001b[1;34m(self, message, stream, audio, images, videos, messages, stream_intermediate_steps, **kwargs)\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2060\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\n\u001b[0;32m   2061\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m   2062\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2069\u001b[0m     )\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(resp)\n",
      "File \u001b[1;32mc:\\Users\\mayur\\Desktop\\Project\\phidata AI Agents\\venv\\Lib\\site-packages\\phi\\agent\\agent.py:1842\u001b[0m, in \u001b[0;36mAgent._run\u001b[1;34m(self, message, stream, audio, images, videos, messages, stream_intermediate_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1837\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_run_response(\n\u001b[0;32m   1838\u001b[0m                     content\u001b[38;5;241m=\u001b[39mmodel_response_chunk\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[0;32m   1839\u001b[0m                     event\u001b[38;5;241m=\u001b[39mRunEvent\u001b[38;5;241m.\u001b[39mtool_call_completed,\n\u001b[0;32m   1840\u001b[0m                 )\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1842\u001b[0m     model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages_for_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1843\u001b[0m     \u001b[38;5;66;03m# Handle structured outputs\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_outputs \u001b[38;5;129;01mand\u001b[39;00m model_response\u001b[38;5;241m.\u001b[39mparsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mayur\\Desktop\\Project\\phidata AI Agents\\venv\\Lib\\site-packages\\phi\\model\\openai\\chat.py:591\u001b[0m, in \u001b[0;36mOpenAIChat.response\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# -*- Generate response\u001b[39;00m\n\u001b[0;32m    590\u001b[0m metrics\u001b[38;5;241m.\u001b[39mresponse_timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 591\u001b[0m response: Union[ChatCompletion, ParsedChatCompletion] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m metrics\u001b[38;5;241m.\u001b[39mresponse_timer\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m    594\u001b[0m \u001b[38;5;66;03m# -*- Parse response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mayur\\Desktop\\Project\\phidata AI Agents\\venv\\Lib\\site-packages\\phi\\model\\openai\\chat.py:343\u001b[0m, in \u001b[0;36mOpenAIChat.invoke\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    341\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from OpenAI API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    344\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    345\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_message(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_kwargs,\n\u001b[0;32m    347\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mayur\\Desktop\\Project\\phidata AI Agents\\venv\\Lib\\site-packages\\phi\\model\\openai\\chat.py:170\u001b[0m, in \u001b[0;36mOpenAIChat.get_client\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     client_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOpenAIClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayur\\Desktop\\Project\\phidata AI Agents\\venv\\Lib\\site-packages\\openai\\_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from phi.agent import Agent\n",
    "from phi.tools.googlesearch import GoogleSearch\n",
    "\n",
    "agent = Agent(\n",
    "    tools=[GoogleSearch()],\n",
    "    # model=Groq(id=\"llama3-70b-8192\"),\n",
    "    description=\"You are a news agent that helps users find the latest news.\",\n",
    "    instructions=[\n",
    "        \"Given a topic by the user, respond with 4 latest news items about that topic.\",\n",
    "        \"Search for 10 news items and select the top 4 unique items.\",\n",
    "        \"Search in English and in French.\",\n",
    "    ],\n",
    "    show_tool_calls=True,\n",
    "    debug_mode=True,\n",
    ")\n",
    "agent.print_response(\"Mistral AI\", markdown=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
